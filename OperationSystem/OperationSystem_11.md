# 운영체제 #11
## 메모리관리
- 왜 메모리관리가 필요하지? 여러 프로그램들이 메모리에 적재되어서 실행되는데, 컴퓨터 메모리는 한정적인 자원이기 때문에 관리가 필요
- 범용 컴퓨터 시스템의 목적
    - CPU의 활용률(Utilization)을 극대화
    - 사용자에게 빠른 응답을 제공
        - 보다 많은 Program을 Memory에 올려서 실행(Multi-Programming)
        - 여러 Program을 동시에 실행시키기 위한 Scheduling 기법 등장
- Memory 관리의 필요성 등장
    - 여러 Program이 동시에 Memory에 적재되어서 실행되면서, Memory를 공유할 필요가 생김
    - Computer의 Memory는 한정된 자원
        - 실행하는 Program이 많아지면 Memory 요구량이 증가
## 주소공간
- 정의(Address Space)
    - Process에서 참조할 수 있는 주소들의 범위(집합)
    - Process와 1:1 관계
    - 사용자 thread는 주소 공간을 공유함
- 주소 버스
    - 메모리의 주소를 나타내는데에 사용하는 비트의 수(32bit 기본)
    - 윈도우가 32bit일 때 4GB까지밖에 Ram을 쓸 수 없다는 말이 있었음 -> 64bit로 바뀌면서 더 많이 사용 가능해짐 -> 주소 버스가 32bit 에서 64bit가 된 것
    - (2<sup>10</sup> = K, 2<sup>30</sup>=G, 2<sup>32</sup>=4기가바이트)
- 주소공간의 크기
    - CPU의 주소 버스(Address Bus)의 크기에 의존
    - 주소 버스가 32bit인 system에서 주소 공간의 크기
        - 2<sup>32</sup>개의 서로 다른 주소에 대한 식별자를 만들 수 있으므로, 0부터(2<sup>32</sup>-1)까지의 주소 범위를 addressing할 수 있음
    - 32bit 주소 버스를 가진 system이 주소 1개당 1byte의 memory를 접근할 수 있다면, 이 System이 address할 수 있는 주소 공간의 크기는 몇 byte인가?
## 물리 주소와 가상 주소
- 스토리지에서 메모리에 할당되지 않은 시점에 프로세스를 메모리에 올릴 때 어떻게 올릴까?
    - 스토리지에서의 주소와 메모리 위에 올라갔을 때의 주소가 구분이 되어야겠구나!!
    - 실제 메모리에 올라갔을 때 사용되는 주소가 물리적 주소
    - 스토리지에서는 어디로 갈 지 모르니까 어쩔 수 없이 0부터 시작하는 주소가 가상 주소
- 물리 주소(Physical Address)
    - 컴퓨터의 메인 메모리를 접근할 때 사용되는 주소
    - 기억 장치의 주소 레지스터에 적재되는 주소
- 가상 주소(Logical Address or Virtual Address)
    - Process의 관점에서 사용하는 주소
    - CPU 관점의 주소는 물리 주소도, 가상 주소도 될 수 있음
        - 어느 Memory Model을 사용하느냐에 따라 달라짐
    - Logical이기 때문에 주소 공간을 의미 있는 단위로 나누어 사용하지 않음
## 초창기 컴퓨터의 주소 관리
- 물리 주소를 Compiile Time에 생성
    - Compiler는 Process가 물리 Memory에서 실행되는 주소를 Compile Time에 알아서 절대 코드를 생성한다.
    - 시작 주소의 위치가 바뀔 경우에는 다시 Compile을 해야 한다.
    - ex. MS-DOS의 .COM 형식의 Program
- 다양한 Program이 실행됨에 따라 Compile Time에 물리 주소를 정하기가 어려워짐
    - 1개의 Program이 실행될 경우 문제가 없음
    - Multiprogramming의 경우, Compile Time시에 결정된 주소는 다른 Program과 동시에 Memory에 load하기 어려움
        - 가상 주소를 생성하기 시작함
## 주소 결정
- Compile Time
    - Compiler가 Symbol Table을 만들고 주소는 Symbol Table Relative한 주소로 이루어짐
    - Compile된 Object 파일은 주소 0부터 시작함(Relocatable)
    - 변수 같은 것을 찾아가기 위해서는 symbol table을 거쳐서 가야한다는 특징이 있음
        - 주소를 만들수는 있는데, 실제로 활용하기에는 어려움이 있다.
- Link Time
    - Object 파일들과 System에서 제공하는 Library들을 묶어서 Symbol Table에 의존적이지 않은 주소를 만들어 냄
    - Link의 결과로 하나의 Executable파일이 만들어진 주소는 0부터 시작함
    - Executable은 하나의 주소 공간으로 0부터 시작함
- Load Time
    - Program의 실행을 위해 Loader는 Executable을 Memory로 load한다.
    - 주소 공간 전체가 Memory에 올라간다면, Load시에 물리 주소에 대한 Binding이 일어난다.
        - Program은 Relocatable 주소로 되어 있기 때문에 뒤에 배울 Base Register를 통해서 물리 주소로 바꾸어 실행하게 된다.
            - 시작 지점이 어디인지 알려주는 것이 Base Register
    - 만일 Progra의 시작 주소를 바꾸려면, 다시 Load를 해야 한다.
    - Load하는 시점에 p1의 가상주소 0이 1024에 매핑 -> 만약 p1이 내려갔다가 다시 왔을 때 1024에 다른 프로세스가 있으면 base register를 다른 곳에 두고 다시 로드해줘야함
- Execution Time
    - Process가 실행 될 때 물리 주소가 바뀌는 경우, 물리 주소에 대한 Binding은 Process가 실행될 때 일어난다.
        - 나중에 배울 Paging이나 Swapping을 통해서 Process가 올려지는 Memory의 물리 주소는 바뀔 수 있다.
    - 이러한 형태의 주소 결정 방법을 사용하기 위해서 MMU와 같은 특별한 하드웨어가 필요
    - 대부분 General Purpose운영체제에서는 이 방법을 사용
    - 프로세스가 실행될 때 메모리 전체가 아닌 일부만 참조
        - 실행하는 순간에 실행되는 부분만 참조하면 어떨까?
        - 주소 결정이 복잡해졌으니 MMU같은 특별한 하드웨어 필요
        - => 가상주소 자체는 Link타임에 결정되 되지만 물리주소는 Runtime에 결정된다.
## CPU에서 사용하는 주소에 따른 변환 방법
- CPU에서 Physical realtive address를 사용하는 경우
    - Program 내 Instruction들의 주소를 시작 주소(Base Address)로 부터의 상대적인 Offset으로 표현하는 방법
    - 시작 주소가 결정되면 시작 주소 + 상대 주소의 합으로 절대 주소를 생성할 수 있다.
    - ex. 0~1024까지가 p1의 주소 공간이고, 1024에 매핑이 되었으면 0+1024rk 물리 주소
        - 만약 245부터 시작하면 245+1024
- CPU에서 Virtual Address를 사용하는 경우
    - virtual address를 Physical Address로 변환하는 Translation 과정이 필요하다.
    - 이 Translation의 속도가 매우 중요
    - 이 Translation을 담당하는 하드웨어가 MMU
## Memory Management Unit(MMU)
- virtual address와 physical address간의 변환을 수행하는 hardware 장치
- MMU는 CPU로부터 받은 virtual address를 physical address로 번역하여 memory로 보낸다.
- CPU는 MMU에서 virtual address를 보낸다.
- 문제
    1. 프로세스 하나에서 내부의 어떤 것은 어디 메모리에, 어떤 것은 어디에 들어가야하는 지 잘 Mapping하는 것이 필요
    2. 프로세스가 점점 많아지고, 프로세스의 메모리 합이 이미 20GB라 할 때, 16GB에 어떻게 올려서 사용할 것인가? 프로세스의 수는 늘어나는데, 용량은 한정

## 가상 메모리
- 정의
    - Memory로서 실제 존재하지는 않지만, 사용자에게 Memory로서의 역할을 하는 Memory(Virtual)
- Basic Data
    - Process가 수행 되기 위해서 Program의 모든 부분이 실제 메모리(Physical Memory)에 있을 필요는 없다.
    - 현재 실행되고 있는 Code부분만이 실제 Memory에 있으면 Process는 실행이 가능
- 구현
    - 가상 메모리와 물리 메모리의 매핑 관계 정보를 저장하는 table을 둔다(MMU가 관리-page table)
    - table에서 매핑된 것이 없으면 Secondary Storage에 들어가서 어디에 매핑 될 지 정한 후 사용
    - 만약 mapping이 중복되는 경우(여러 logical memory가 같은 physical address에 매핑되었을 경우) MMU가 관리
        - -> 프로세스 덩어리가 잘 잘려져있어야 한다. -> 4kb정도로 나누고, 이것을 page라 하자. 물리 메모리에서의 4kb는 page와 구분하기 위해 frame이라 하자.
        - => page table은 page와 frame의 매핑 정보를 갖고 있는 테이블이구나.
## Paging
- 주소 공간을 동일한 크기인 Page로 나누어 관리
    - 보통 1 Page의 크기는 4kb로 나누어 사용
    - 프레임(frame)
        - 물리 Memory를 고정된 크기로 나누었을 때, 하나의 Block
    - 페이지(Page)
        - 가상 Memory를 고정된 크기로 나누었을 때, 하나의 Block
    - 각각의 프레임 크기와 페이지 크기는 같다.
- Page가 하나의 Frame을 할당 받으면, 물리 Memory에 위치하게 된다.
    - Frame을 할당 받지 못한 Page들은 외부 저장장치(Backing Storage)에 저장된다.
        - Backing Storage도 Page, Frame과 같은 크기로 나누어져 있다.
- page의 관리 : 각 프로세스마다 자신 page들의 table은 하나씩 가지고있음
    - table내에 page의 주소 존재
## 중간점검
1. 128MB의 물리 Memory를 4kb 단위로 Paging 하려고 하면, 몇 개의 Frame이 필요한가?
    - MB가 2<sup>20</sup>, 128 = 2<sup>7</sup>, 4kb = 2<sup>12</sup> -> 27-12
    - 2<sup>15</sup>개의 frame 필요
2. 4GB의 Logical Address를 Paging하려고 하면, 총 몇 개의 Page가 필요한가?(page크기 = 4kb)
    - 2<sup>10</sup> = K, 2<sup>20</sup>=M, 2<sup>30</sup>=G, 2<sup>40</sup>=T
    - 2<sup>2</sup> * 2<sup>30</sup> = 2<sup>32</sup>, 4kb = 2<sup>12</sup>, 32-12
    - 2<sup>20</sup> = 1MB
3. Page의 크기가 4kb일때, 한 Page의 Memory를 Access하기 위한 주소 bit는 몇 bit?
    - 위의 것들은 byte 단위
    - log<sub>2</sub>4k -> log<sub>2</sub>2<sup>12</sup> -> 12bit
- 12bit가 memory를 access하기 위한 주소 bit라면, 32bit라 할 때 남은 20bit는 page를 관리할 때 쓸 수 있겠다 -> 2번의 답이 그것(4GB를 사용한 이유)
## Page Table
- 페이지 테이블
    - 각 Process의 Page 정보를 저장함
        - Process마다 하나의 Page Table을 가짐
    - Index : Page 번호
    - 내용 : 해당 Page에 할당된 물리 Memory(Frame)의 시작 주소
        - 이 시작 주소와 Page 주소를 결합하여 원하는 Data가 있는 물리 Memory 주소를 알 수 있음
- Page table의 구현
    - Page Table은 물리 memory에 위치함
    - Page Table 기준 레지스터(PTBR : Page Table Base Register)가 물리 Memory내의 Page Table을 가리킴
    - Page Table 길이 레지스터(PTLF : Page Table Length Register)가 Page table의 Size를 나타냄
- LA-PA Mapping
- Page Table을 이용한 주소 변환
- Page Table Entry(PTE)
    - Page Table의 Record
    - 각 필드 내용
        - Page Base Address
            - 해당 Page에 할당된 Frame의 시작 주소
            - 이를 통해 물리 Memory에 접근할 수 있음
        - Flag Bits
            - Accessed Bit : Page에 대한 접근이 있었는지
            - Dirty Bit : Page 내용의 변경이 있었는지
            - Present Bit : 현재 Page에 할당된 Frame이 있는지
            - Read/Write Bit : 읽기/쓰기에 대한 권한 표시
        - 그 외 구성에 따라 여러 내용이 포함될 수 있다.
## Translation Look-aside Buffer(TLB)
- CPU와 memory의 속도 차이가 있기 때문에 cpu 입장에서는 memory에 접근하는 overhead가 문제가 됨 -> 이거 굉장히 비효율적인데? -> 캐싱을 하자
- Paging 방법에서는 Data로의 접근이 항상 두 번의 Memory 접근을 거쳐야 함
    - Page Table에 한 번, 물리 Memory 내의 Data에 한 번
    - Memory 접근 속도를 크게 떨어뜨림
- 해결방법 - TLB in MMU
    - Page Table을 이용해 변환된 주소를 TLB에 저장해 둠
    - 다음 접근 시에는 TLB에 저장된 값을 이용하여 빠르게 변환된 주소를 얻을 수 있음
        - TLB는 Register이기 때문에, 빠른 수행이 가능함
    - TLB Hit Ratio
        - TLB내에서 원하는 주소를 찾을 수 있는 확률
        - 높을 수록 Memory 접근 속도를 향상시킬 수 있음
    - TLB를 먼저 보고, 이것이 있으면 그냥 frame을 찾아서 Physical memory에 접근하고, 아니라면 page table을 거쳐서 frame을 찾고 physical memory에 접근
## Multilevel Page Table
- 다단계 Page Table의 필요성
    - System의 발전에 따라 가상 주소 공간도 매우 큰 용량을 요구하게 됨
    - 그로 인해 Page Table의 크기가 커지고, 그 차지하는 공간에 의해 Paging이 잘 이루어질 수 없게 되고 있음
    - 예) 32 bit 가상 주소 공간을 가지는 system
        - page의 크기 : 4kb(2<sup>12</sup>)의 경우,
        - page table의 크기 : 1M(2<sup>20</sup>) * 4B = 4MB
            - page table entry의 값 하나는 보통 4B를 차지함
    - Page Table 자체도 Paging된 공간에 저장하자
- 2 Level Page Table 구현
    - Outer Page Table을 하나 더 두어, Page Table들을 가리키도록 한다.
    - ex. 앞서의 예에서, 20bit를 차지하는 Page 번호를 다시 아래와 같이 나눈다.
        - 10 bit page 번호
        - 10 bit page 주소
        - 결국 32bit주소는 20bit의 page number(10-번호, 10-주소) + 12 bit의 page offset가 된다.
- Page Table Level과 Memory 성능
    - 하나의 주소공간을 Mapping하는 PT이 차지하는 Memory
        - 2 Level인 경우와 1 Level인 경우 PT 전체가 차지하는 Memory
    - PT의 Level이 많은 경우 장점
        - Level이 3인 경우 생각해보기
        - 어떨 때 PT가 차지하는 Memory가 줄어들까? -> 계속 참조하는 것만 참조하면 효울적
    - 단점
        - 메모리에 접근을 한느 횟수가 늘어나기에 Table Walk에 걸리는 시간이 증가
## Inverted Page Table
- Multilevel Page Table에서와 같은 Page Table의 용량 증가 문제를 해결하기 위한 다른 방법
    - 64bit 주소 공간의 System에서 Multilevel Paging을 위한 정보의 크기는 32bit에 비해 현격하게 증가됨
- 해결 방법
    - 아무리 가상 Memory 공간이 크더라도, 물리 Memory의 크기에는 한계가 있음
    - 모든 물리 Memory는 가상 Memory의 page에 Mapping될 확률이 높음
    - -> page table의 크기 자체를 page의 개수나 크기가 기준이 아니라 physical memory기준으로 하자!!
- Think Different
    - 기존 방식은 Page #을 이용하여 Frame #을 검색
    - Inverted Page Table은 CPU에서 참조하는 Address와 PID의 조합으로 Page ID를 만들어 Page Table 내에서 Page ID(process id + page번호)를 검색함
        - Page ID를 발견하면, 해당 Frame #를 Logical Address 공간으로 Mapping
- 구현
    - System 전체에 하나의 Page Table만 둔다
        - Page Table Index : Frame의 번호
        - Page Table 내용 : Process 번호(Process ID)와 Page 번호, Page 주소를 함께 넣음
        - ex. 12번 process의 23번 page, 34번째 Data
            - page table을 처음부터 검색하여 12,23의 내용을 가지는 부분의  index를 보고 frame을 알 수 있음
                - 찾고자 하는 data와 배열의 content가 일치함을 확인했을 때, 그 배열의 index가 검색 결과
            - 해당 frame의 34번째 data에 접근
        - page table은 보다 적은 용량을 차지하지만, pid+p를 전부 비교하면서 검색하기에 시간이 오래 걸린다.
            - 해쉬 테이블을 사용하면 단축 가능
## Demand Paging
- Demand Paging이란?
    - Process의 실행을 위한 모든 Page를 Memory에 올리지 않고, 필요한 Page의 요청이 발생할 때 메모리에 올리는 Paging 기법
- Paging Service를 통해서 한 Process에 필요한 Page를 Memory와 Secondary Storage간에 이동시킴
- Valid and Invalid Page
- Demand Paging의 장점
    - 실행을 위한 물리 Memory 구성의 시간이 줄어든다.
    - Process의 전체 이미지를 Memory에 올리지 않기 때문에, 실제 필요한 전체 물리 Memory의 양을 줄일 수 있다.
- Demand Paging의 단점
    - 참조하려는 Page가 Valid한 경우
        - 참조하고자 하는 Page가 실제 물리 Memory에 있기 때문에 정상적인 참조
    - 참조하려는 Page가 invalid한 경우
        - 참조하고자 하는 Page가 실제 물리 Memory에 없으므로 이에 대한 처리 필요
        - Page Fault발생
- Demand Paging을 하기 위해서 Page Table에 어떠한 정보가 더 필요할까?
    - Present bit가 필요하다
- Page Fault
    - Process가 Page를 참조하였을 때 해당 Page가 할당 받은 Frame이 없는 경우
        - 있는 경우(present bit == valid)
            - page base address를 통해 해당 Frame에 접근
        - 없는 경우(present bit == invalid)
            - page fault 발생
                - frame을 새로 할당 받아야 함
                - page fault handler 수행
    - page fault handler가 수행하는 내용
        - 새로운 Frame을 할당 받음
        - Backing Storage에서 Page의 내용을 다시 Frame에 불러들인다.
        - Page Table을 재구성한다.
        - Process의 작업을 재시작한다.
    - page fault는 trap으로 수행됨
        - 왜? 이건 동기적인 이벤트이다. Process가 실행되는 도중에 page fault(I/O)가 발생하면 잠깐 그걸 처리해주고 어차피 다시 돌아와야한다. -> 정보를 저장할 필요 없음 -> Trap으로 처리
    - page fault발생 빈도는 프레임의 개수와 반비례함
    - page fault가 발생할 것 같은 시점은 언제일까?
        - 현재 큰 덩어리들이 실행되다가 다음의 어떤 덩어리들로 전이되어야 할 때
    - Locality
        - ex. 코딩을 할 때 배열을 만들고 반복문의 index로 많이 접근함
            1. 현재 접근한 메모리를 다시 접근할 가능성이 높다. -> Temporal Locality
            2. Loop를 도는 동안에는 그 메모리 영역과 그 근처에서만 접근될 가능성이 높다. -> Spatial Locality
        - 이러한 locality를 활용한 것이 caching이다.
        - page도 필요한 것만 메모리에 올려놓고 쓰기 때문에 이런 locality에 의해서 한동안은 비슷한 영역에서만 실행되다가 이 loop가 빠져나가면 다시 사용됨
    - Working Set
        - 정의
            - 어떤 시간 Window 동안에 접근한 Page들의 집합
            - 시간마다 working set이 변함
            - 적당한 window를 잡으면, working set은 locality를 나타냄
        - Trashing
            - Process의 실행 시간 중, page fault를 처리하는 시간이 execution 시간보다 긴 상황
        - 이 working set을 얼마나 잘 책정해서 overhead를 줄일 것인지가 관건!!